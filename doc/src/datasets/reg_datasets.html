<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>src.datasets.reg_datasets API documentation</title>
<meta name="description" content="Contain a simple linear and logistic regression datasets parameters estimation.." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.datasets.reg_datasets</code></h1>
</header>
<section id="section-intro">
<p>Contain a simple linear and logistic regression datasets parameters estimation..</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Contain a simple linear and logistic regression datasets parameters estimation..&#34;&#34;&#34;


from typing import Callable, Optional, Tuple

import numpy as np
from numpy import ndarray
from scipy.linalg import toeplitz
from sklearn.preprocessing import StandardScaler

import torch
from torch import Tensor
from torch.utils.data import Dataset


class LinRegDataset(Dataset):
    &#34;&#34;&#34;Dataset of generated linear regression data.&#34;&#34;&#34;

    def __init__(self, data: Tuple[ndarray, ...], transform: Optional[Callable] = None):
        &#34;&#34;&#34;Initialize a dataset of linear regression data.

        Parameters
        ----------
        data : tuple of numpy.ndarray
            Tuple containing the samples and corresponding labels.

        transform : callable, optional
            A transform to apply to the data.
        &#34;&#34;&#34;
        X, y = data
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))

        self.transform = transform

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;Return the length of the dataset.

        Returns
        -------
        length : int
            Length of the dataset.
        &#34;&#34;&#34;
        length = len(self.y)

        return length

    def __getitem__(self, index) -&gt; Tuple[Tensor, ...]:
        &#34;&#34;&#34;Return data point(s) at position **idx**.

        Parameters
        ----------
        index : int or list of int
            Index or list of indices of selected data points.
        &#34;&#34;&#34;
        samples = self.X[index]
        labels = self.y[index].flatten()

        return samples, labels


class LogRegDataset(Dataset):
    &#34;&#34;&#34;Dataset of generated logistic regression data.&#34;&#34;&#34;

    def __init__(self, data: Tuple[ndarray, ...], transform: Optional[Callable] = None):
        &#34;&#34;&#34;Initialize a dataset of logistic regression data.

        Parameters
        ----------
        data : tuple of numpy.ndarray
            Tuple containing the samples and corresponding labels.

        transform : callable, optional
            A transform to apply to the data.
        &#34;&#34;&#34;
        X, y = data
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.int64))

        self.transform = transform

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;Return the length of the dataset.

        Returns
        -------
        length : int
            Length of the dataset.
        &#34;&#34;&#34;
        length = len(self.y)

        return length

    def __getitem__(self, index) -&gt; Tuple[Tensor, ...]:
        &#34;&#34;&#34;Return data point(s) at position **idx**.

        Parameters
        ----------
        index : int or list of int
            Index or list of indices of selected data points.
        &#34;&#34;&#34;
        samples = self.X[index]
        labels = self.y[index].flatten()

        return samples, labels


def simu_linreg(n_features: int = 20, n_samples: int = 10000, corr: float = 0.3,
                std: float = 0.5) -&gt; Tuple[Tuple[ndarray, ...], ...]:
    &#34;&#34;&#34;Simulation of a linear regression model with Gaussian features.

    Parameters
    ----------
    n_features : int
        Number of features to simulate.

    n_samples : int, default=1000
        Number of samples to simulate.

    corr : float, default=0.5
        Correlation of the features.

    std : float, default=0.5
        Standard deviation of the noise.

    Returns
    -------
    train_set : tuple of numpy.ndarray
        Training data.

    test_set : tuple of numpy.ndarray
        Test data.
    &#34;&#34;&#34;
    # Weight creation
    w0 = np.random.normal(loc=2, scale=1, size=n_features)

    # Construction of a covariance matrix
    cov = toeplitz(corr ** np.arange(0, n_features))

    # Simulation of features
    X = np.random.multivariate_normal(np.zeros(n_features), cov, size=n_samples)

    # Simulation of the labels
    y = X.dot(w0) + std * np.random.randn(n_samples)

    # Create training and test sets
    train_size = int(0.8*n_samples)

    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    # Rescaling the data
    sc = StandardScaler()

    X_y_train = np.concatenate((X_train, np.reshape(y_train, (len(y_train), 1))), axis=1)
    X_y_test = np.concatenate((X_test, np.reshape(y_test, (len(y_test), 1))), axis=1)

    X_y_train = sc.fit_transform(X_y_train)
    X_y_test = sc.transform(X_y_test)

    X_train, X_test = X_y_train[:, :-1], X_y_test[:, :-1]
    y_train, y_test = X_y_train[:, -1], X_y_test[:, -1]

    # Dataset format
    train_set = (X_train, y_train)
    test_set = (X_test, y_test)

    return train_set, test_set


def simu_logreg(n_features: int = 20, n_samples: int = 10000,
                corr: float = 0.3) -&gt; Tuple[Tuple[ndarray, ...], ...]:
    &#34;&#34;&#34;Simulation of a logistic regression model with Gaussian features and a Toeplitz covariance.

    Parameters
    ----------
    n_features : int
        Number of features to simulate.

    n_samples : int, default=1000
        Number of samples to simulate.

    corr : float, default=0.5
        Correlation of the features.

    Returns
    -------
    train_set : tuple of numpy.ndarray
        Training data.

    test_set : tuple of numpy.ndarray
        Test data.
    &#34;&#34;&#34;
    # Weight creation
    w0 = np.random.normal(loc=2, scale=1, size=n_features)

    # Construction of a covariance matrix
    cov = toeplitz(corr ** np.arange(0, n_features))

    # Simulation of features
    X = np.random.multivariate_normal(np.zeros(n_features), cov, size=n_samples)

    # Simulation of the labels
    p = sigmoid(X.dot(w0))
    y = np.random.binomial(1, p, size=n_samples)

    # Create training and test sets
    train_size = int(0.8*n_samples)

    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    # Rescaling the data
    sc = StandardScaler()

    X_y_train = np.concatenate((X_train, np.reshape(y_train, (len(y_train), 1))), axis=1)
    X_y_test = np.concatenate((X_test, np.reshape(y_test, (len(y_test), 1))), axis=1)

    X_y_train = sc.fit_transform(X_y_train)
    X_y_test = sc.transform(X_y_test)

    X_train, X_test = X_y_train[:, :-1], X_y_test[:, :-1]
    y_train, y_test = X_y_train[:, -1], X_y_test[:, -1]

    # Dataset format
    train_set = (X_train, y_train)
    test_set = (X_test, y_test)

    return train_set, test_set


def sigmoid(t: ndarray) -&gt; ndarray:
    &#34;&#34;&#34;Sigmoid function.

    Parameters
    ----------
    t : numpy.ndarray
        Inputs.

    Returns
    -------
    sig_t : numpy.ndarray
        Sigmoid of inputs.
    &#34;&#34;&#34;
    sig_t = np.zeros(t.shape)

    # Separate where t is nonnegative
    pos_indices = t &gt; 0

    sig_t[pos_indices] = 1/(1 + np.exp(-t[pos_indices]))
    exp_t = np.exp(t[~pos_indices])
    sig_t[~pos_indices] = exp_t/(1 + exp_t)

    return sig_t</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.datasets.reg_datasets.sigmoid"><code class="name flex">
<span>def <span class="ident">sigmoid</span></span>(<span>t: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Sigmoid function.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>t</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Inputs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>sig_t</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Sigmoid of inputs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sigmoid(t: ndarray) -&gt; ndarray:
    &#34;&#34;&#34;Sigmoid function.

    Parameters
    ----------
    t : numpy.ndarray
        Inputs.

    Returns
    -------
    sig_t : numpy.ndarray
        Sigmoid of inputs.
    &#34;&#34;&#34;
    sig_t = np.zeros(t.shape)

    # Separate where t is nonnegative
    pos_indices = t &gt; 0

    sig_t[pos_indices] = 1/(1 + np.exp(-t[pos_indices]))
    exp_t = np.exp(t[~pos_indices])
    sig_t[~pos_indices] = exp_t/(1 + exp_t)

    return sig_t</code></pre>
</details>
</dd>
<dt id="src.datasets.reg_datasets.simu_linreg"><code class="name flex">
<span>def <span class="ident">simu_linreg</span></span>(<span>n_features: int = 20, n_samples: int = 10000, corr: float = 0.3, std: float = 0.5) ‑> Tuple[Tuple[numpy.ndarray, ...], ...]</span>
</code></dt>
<dd>
<div class="desc"><p>Simulation of a linear regression model with Gaussian features.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n_features</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of features to simulate.</dd>
<dt><strong><code>n_samples</code></strong> :&ensp;<code>int</code>, default=<code>1000</code></dt>
<dd>Number of samples to simulate.</dd>
<dt><strong><code>corr</code></strong> :&ensp;<code>float</code>, default=<code>0.5</code></dt>
<dd>Correlation of the features.</dd>
<dt><strong><code>std</code></strong> :&ensp;<code>float</code>, default=<code>0.5</code></dt>
<dd>Standard deviation of the noise.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>train_set</code></strong> :&ensp;<code>tuple</code> of <code>numpy.ndarray</code></dt>
<dd>Training data.</dd>
<dt><strong><code>test_set</code></strong> :&ensp;<code>tuple</code> of <code>numpy.ndarray</code></dt>
<dd>Test data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simu_linreg(n_features: int = 20, n_samples: int = 10000, corr: float = 0.3,
                std: float = 0.5) -&gt; Tuple[Tuple[ndarray, ...], ...]:
    &#34;&#34;&#34;Simulation of a linear regression model with Gaussian features.

    Parameters
    ----------
    n_features : int
        Number of features to simulate.

    n_samples : int, default=1000
        Number of samples to simulate.

    corr : float, default=0.5
        Correlation of the features.

    std : float, default=0.5
        Standard deviation of the noise.

    Returns
    -------
    train_set : tuple of numpy.ndarray
        Training data.

    test_set : tuple of numpy.ndarray
        Test data.
    &#34;&#34;&#34;
    # Weight creation
    w0 = np.random.normal(loc=2, scale=1, size=n_features)

    # Construction of a covariance matrix
    cov = toeplitz(corr ** np.arange(0, n_features))

    # Simulation of features
    X = np.random.multivariate_normal(np.zeros(n_features), cov, size=n_samples)

    # Simulation of the labels
    y = X.dot(w0) + std * np.random.randn(n_samples)

    # Create training and test sets
    train_size = int(0.8*n_samples)

    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    # Rescaling the data
    sc = StandardScaler()

    X_y_train = np.concatenate((X_train, np.reshape(y_train, (len(y_train), 1))), axis=1)
    X_y_test = np.concatenate((X_test, np.reshape(y_test, (len(y_test), 1))), axis=1)

    X_y_train = sc.fit_transform(X_y_train)
    X_y_test = sc.transform(X_y_test)

    X_train, X_test = X_y_train[:, :-1], X_y_test[:, :-1]
    y_train, y_test = X_y_train[:, -1], X_y_test[:, -1]

    # Dataset format
    train_set = (X_train, y_train)
    test_set = (X_test, y_test)

    return train_set, test_set</code></pre>
</details>
</dd>
<dt id="src.datasets.reg_datasets.simu_logreg"><code class="name flex">
<span>def <span class="ident">simu_logreg</span></span>(<span>n_features: int = 20, n_samples: int = 10000, corr: float = 0.3) ‑> Tuple[Tuple[numpy.ndarray, ...], ...]</span>
</code></dt>
<dd>
<div class="desc"><p>Simulation of a logistic regression model with Gaussian features and a Toeplitz covariance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n_features</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of features to simulate.</dd>
<dt><strong><code>n_samples</code></strong> :&ensp;<code>int</code>, default=<code>1000</code></dt>
<dd>Number of samples to simulate.</dd>
<dt><strong><code>corr</code></strong> :&ensp;<code>float</code>, default=<code>0.5</code></dt>
<dd>Correlation of the features.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>train_set</code></strong> :&ensp;<code>tuple</code> of <code>numpy.ndarray</code></dt>
<dd>Training data.</dd>
<dt><strong><code>test_set</code></strong> :&ensp;<code>tuple</code> of <code>numpy.ndarray</code></dt>
<dd>Test data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simu_logreg(n_features: int = 20, n_samples: int = 10000,
                corr: float = 0.3) -&gt; Tuple[Tuple[ndarray, ...], ...]:
    &#34;&#34;&#34;Simulation of a logistic regression model with Gaussian features and a Toeplitz covariance.

    Parameters
    ----------
    n_features : int
        Number of features to simulate.

    n_samples : int, default=1000
        Number of samples to simulate.

    corr : float, default=0.5
        Correlation of the features.

    Returns
    -------
    train_set : tuple of numpy.ndarray
        Training data.

    test_set : tuple of numpy.ndarray
        Test data.
    &#34;&#34;&#34;
    # Weight creation
    w0 = np.random.normal(loc=2, scale=1, size=n_features)

    # Construction of a covariance matrix
    cov = toeplitz(corr ** np.arange(0, n_features))

    # Simulation of features
    X = np.random.multivariate_normal(np.zeros(n_features), cov, size=n_samples)

    # Simulation of the labels
    p = sigmoid(X.dot(w0))
    y = np.random.binomial(1, p, size=n_samples)

    # Create training and test sets
    train_size = int(0.8*n_samples)

    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    # Rescaling the data
    sc = StandardScaler()

    X_y_train = np.concatenate((X_train, np.reshape(y_train, (len(y_train), 1))), axis=1)
    X_y_test = np.concatenate((X_test, np.reshape(y_test, (len(y_test), 1))), axis=1)

    X_y_train = sc.fit_transform(X_y_train)
    X_y_test = sc.transform(X_y_test)

    X_train, X_test = X_y_train[:, :-1], X_y_test[:, :-1]
    y_train, y_test = X_y_train[:, -1], X_y_test[:, -1]

    # Dataset format
    train_set = (X_train, y_train)
    test_set = (X_test, y_test)

    return train_set, test_set</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.datasets.reg_datasets.LinRegDataset"><code class="flex name class">
<span>class <span class="ident">LinRegDataset</span></span>
<span>(</span><span>data: Tuple[numpy.ndarray, ...], transform: Optional[Callable] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Dataset of generated linear regression data.</p>
<p>Initialize a dataset of linear regression data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>tuple</code> of <code>numpy.ndarray</code></dt>
<dd>Tuple containing the samples and corresponding labels.</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>A transform to apply to the data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LinRegDataset(Dataset):
    &#34;&#34;&#34;Dataset of generated linear regression data.&#34;&#34;&#34;

    def __init__(self, data: Tuple[ndarray, ...], transform: Optional[Callable] = None):
        &#34;&#34;&#34;Initialize a dataset of linear regression data.

        Parameters
        ----------
        data : tuple of numpy.ndarray
            Tuple containing the samples and corresponding labels.

        transform : callable, optional
            A transform to apply to the data.
        &#34;&#34;&#34;
        X, y = data
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))

        self.transform = transform

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;Return the length of the dataset.

        Returns
        -------
        length : int
            Length of the dataset.
        &#34;&#34;&#34;
        length = len(self.y)

        return length

    def __getitem__(self, index) -&gt; Tuple[Tensor, ...]:
        &#34;&#34;&#34;Return data point(s) at position **idx**.

        Parameters
        ----------
        index : int or list of int
            Index or list of indices of selected data points.
        &#34;&#34;&#34;
        samples = self.X[index]
        labels = self.y[index].flatten()

        return samples, labels</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="src.datasets.reg_datasets.LinRegDataset.functions"><code class="name">var <span class="ident">functions</span> : Dict[str, Callable]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="src.datasets.reg_datasets.LogRegDataset"><code class="flex name class">
<span>class <span class="ident">LogRegDataset</span></span>
<span>(</span><span>data: Tuple[numpy.ndarray, ...], transform: Optional[Callable] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Dataset of generated logistic regression data.</p>
<p>Initialize a dataset of logistic regression data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>tuple</code> of <code>numpy.ndarray</code></dt>
<dd>Tuple containing the samples and corresponding labels.</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>callable</code>, optional</dt>
<dd>A transform to apply to the data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LogRegDataset(Dataset):
    &#34;&#34;&#34;Dataset of generated logistic regression data.&#34;&#34;&#34;

    def __init__(self, data: Tuple[ndarray, ...], transform: Optional[Callable] = None):
        &#34;&#34;&#34;Initialize a dataset of logistic regression data.

        Parameters
        ----------
        data : tuple of numpy.ndarray
            Tuple containing the samples and corresponding labels.

        transform : callable, optional
            A transform to apply to the data.
        &#34;&#34;&#34;
        X, y = data
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.int64))

        self.transform = transform

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;Return the length of the dataset.

        Returns
        -------
        length : int
            Length of the dataset.
        &#34;&#34;&#34;
        length = len(self.y)

        return length

    def __getitem__(self, index) -&gt; Tuple[Tensor, ...]:
        &#34;&#34;&#34;Return data point(s) at position **idx**.

        Parameters
        ----------
        index : int or list of int
            Index or list of indices of selected data points.
        &#34;&#34;&#34;
        samples = self.X[index]
        labels = self.y[index].flatten()

        return samples, labels</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="src.datasets.reg_datasets.LogRegDataset.functions"><code class="name">var <span class="ident">functions</span> : Dict[str, Callable]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="Directory index" href="index.html">
<img src="logo.png" alt="">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.datasets" href="index.html">src.datasets</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.datasets.reg_datasets.sigmoid" href="#src.datasets.reg_datasets.sigmoid">sigmoid</a></code></li>
<li><code><a title="src.datasets.reg_datasets.simu_linreg" href="#src.datasets.reg_datasets.simu_linreg">simu_linreg</a></code></li>
<li><code><a title="src.datasets.reg_datasets.simu_logreg" href="#src.datasets.reg_datasets.simu_logreg">simu_logreg</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.datasets.reg_datasets.LinRegDataset" href="#src.datasets.reg_datasets.LinRegDataset">LinRegDataset</a></code></h4>
<ul class="">
<li><code><a title="src.datasets.reg_datasets.LinRegDataset.functions" href="#src.datasets.reg_datasets.LinRegDataset.functions">functions</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.datasets.reg_datasets.LogRegDataset" href="#src.datasets.reg_datasets.LogRegDataset">LogRegDataset</a></code></h4>
<ul class="">
<li><code><a title="src.datasets.reg_datasets.LogRegDataset.functions" href="#src.datasets.reg_datasets.LogRegDataset.functions">functions</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>