<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>src API documentation</title>
<meta name="description" content="Source code for our evaluation of SignSGD against blind and Byzantine adversaries …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>src</code></h1>
</header>
<section id="section-intro">
<p>Source code for our evaluation of SignSGD against blind and Byzantine adversaries.</p>
<h1 id="signsgd-fault-tolerance-to-blind-and-byzantine-adversaries">SignSGD: Fault-Tolerance to Blind and Byzantine Adversaries</h1>
<p>Team: Jason Akoun, Sébastien Meyer</p>
<p>In this project, we implemented the SignSGD algorithm as described by Bernstein, Wang, Azizzadenesheli and Anandkumar in their 2018 paper <a href="https://arxiv.org/abs/1802.04434"><em>SignSGD: Compressed Optimisation for Non-Convex Problems</em></a>. The 2019 paper <a href="https://arxiv.org/abs/1810.05291"><em>SignSGD with Majority Vote is Communication Efficient and Fault Tolerant</em></a> from Bernstein, Zhao, Azizzadenesheli and Anandkumar also extends the properties of SignSGD by proving tolerance to blind adversaries. </p>
<p>Our simple implementation aimed at assessing the convergence and fault-tolerance of SignSGD. Therefore, we have evaluated how SignSGD might be able to resist to attacks from Byzantine adversaries. Our written report is available at <em>report/report.pdf</em> and includes a brief description of our implementation choices, our theoretical proof of a upper bound for the convergence rate after relaxing an assumption from the second paper and a summary of our experimental results.</p>
<p>Please refer to the following sections for more information about the package usage:</p>
<ol>
<li><a href="#some-results">Some results</a></li>
<li><a href="#installation-instructions">Installation</a></li>
<li><a href="#package-description">Description</a></li>
<li><a href="#package-usage">Usage via command lines</a></li>
<li><a href="#documentation">Documentation</a></li>
</ol>
<h2 id="some-results">Some Results</h2>
<p>A more extensive explanation of our implementation choices and experimental results can be found in our report: <em>report/report.pdf</em>.</p>
<h3 id="a-more-general-theoretical-bound">A more general theoretical bound</h3>
<p>Our two main theoretical results are shown below.</p>
<p><img alt="alt text" src="report/figures/lemma1bis.png"></p>
<p><img alt="alt text" src="report/figures/theorem2bis.png"></p>
<h3 id="experimental-results">Experimental results</h3>
<p>We compared the efficiency of the optimizers on basic datasets which are linear and logistic regressions along with simple feed-forward networks. It is still possible to run experiments on more complex datasets such as MNIST, however they will run on CPU and should take longer.</p>
<p>Firstly, we plot the evolution of accuracy on loss for a logistic regression problem, when there are variable numbers of blind adversaries inverting their gradient signs.</p>
<p><img alt="alt text" src="report/figures/logreg_comp_blind.jpg"></p>
<p>From this graph, we can deduce that blind adversaries do not prevent the models from learning. The SignSGD algorithm allows to maintain a better accuracy overall with the number of blind adversaries increasing, and Signum reduces their effect even more. Still, it is important to keep in mind that our dataset and model are basic, therefore the learning process is globally easy.</p>
<p>Then, we show the evolution of loss and accuracy when there are variable numbers of Byzantine adversaries. Byzantine adversaries intercept the gradients of the workers and deploy a strategy. In the case of distributed SGD, a Byzantine can send arbitrary vectors and thus stop the learning process. In the case of SignSGD, Byzantine adversaries are limited to sending signs, therefore they try to bring the aggregation to zero.</p>
<p><img alt="alt text" src="report/figures/logreg_comp_byz.jpg"></p>
<p>Here, we see that our Byzantine strategy does not break SignSGD. Even more, the Signum version of the algorithm allows to resist to our attacks.</p>
<p>Now, we will take a glimpse to a linear regression task. First, we look at the loss when there are variable numbers of blind adversaries.</p>
<p><img alt="alt text" src="report/figures/linreg_comp_blind.jpg"></p>
<p>Again, we see that SignSGD and Signum are better at tolerating attacks from adversaries. </p>
<p>Finally, we will plot the loss when there are variable numbers of Byzantine adversaries.</p>
<p><img alt="alt text" src="report/figures/linreg_comp_byz.jpg"></p>
<p>In the case of distributed SGD, it suffices that one of the worker is a Byzantine adversary to crush the algorithm. However, with our simple regression task, we show that SignSGD and Signum allow the model to learn even with several Byzantine adversaries.</p>
<h2 id="installation-instructions">Installation instructions</h2>
<p>In order to use our package and run your own experiments, we advise you to set up a virtual environment. You will need Python &gt;= 3.9.5 and the <em>virtualenv</em> package:</p>
<pre><code>pip3 install virtualenv
</code></pre>
<p>Then, you can create a virtual environment and switch to it with the following commands:</p>
<pre><code>python3 -m venv myvenv
source myvenv/bin/activate (Linux)
myvenv/Scripts/Activate.ps1 (Windows PowerShell)
</code></pre>
<p>Our experiments were run both on Windows 10 and Linux under CPU. You can install all the needed Python packages with the following command line:</p>
<pre><code>pip3 install -r requirements.txt
</code></pre>
<p>Otherwise, you can manually install the packages into your virtual environment.</p>
<h2 id="package-description">Package description</h2>
<p>Below, we give a brief tree view of our package.</p>
<pre><code>.
├── doc  # contains a generated documentation of src/ in html
├── report  # contains our complete report in pdf format
|   └── figures
├── src  # source code
|   ├── datasets
|   |   ├── __init__.py
|   |   ├── reg_datasets.py  # allows to generate linear and logistic regression data
|   |   └── partition_generator.py  # handle partition generation for processes
|   ├── nn
|   |   ├── __init__.py
|   |   ├── reg_nets.py  # simple nn for linear and logistic regression prediction
|   |   ├── mnist_nets.py  # gathers two models that perform well on MNIST dataset
|   |   └── resnets.py  # gathers ResNet18 and ResNet50 for ImageNet dataset
|   ├── optim
|   |   ├── __init__.py
|   |   ├── distsgd.py  # adapts SGD to a distributed setting (supports adversaries)
|   |   └── signum.py  # implementation of Signum (supports adversaries)
|   ├── __init__.py
|   ├── dist_training.py  # training and evaluation functions for a distributed setting
|   ├── main.py  # main file which you can run on command line to run experiments
|   ├── plot_results.py  # utilitary file which you can run on command line to plot graphs
|   └── utils.py 
├── README.md
└── requirements.txt  # contains the necessary Python packages to run our files
</code></pre>
<h2 id="package-usage">Package usage</h2>
<p>Our implementation of distributed optimizers can be found under the <em>src/optim</em> folder. We have implemented a simple distributed version of SGD as well as the Signum algorithm. Note that, referring to the second paper, SignSGD corresponds to Signum when momentum is equal to zero. Both optimizers are designed to be used in a distributed setting. They can take as parameters a list of processes ranks for blind adversaries and Byzantine adversaries. The processes are expected to be numbered between zero and world size excluded.</p>
<h3 id="model-training-and-evaluation">Model training and evaluation</h3>
<p>You can either use the optimizers in your own code as well as our training and evaluation functions that can be found under <em>src/dist_training.py</em>, or you do have the opportunity to run the <em>src/main.py</em> file. This file allows to train some models for which we guarantee the compatibility with the optimizers and datasets. The command is as follows:</p>
<pre><code>python3 src/main.py &lt;nprocs&gt; &lt;dataset&gt; [options]
</code></pre>
<ul>
<li><code>&lt;nprocs&gt;</code>: Number of processes. This number contains healthy workers as well as eventual adversaries to be set up with optional arguments.</li>
<li><code>&lt;dataset&gt;</code>: Name of the dataset from "linreg", "logreg", "mnist" and "imagenet". The "linreg" and "logreg" datasets are generated internally during the runs and can be used to demonstrate the algorithm. The "mnist" dataset contains 50,000 training and 10,000 test images of size 28x28x1 representing handwritten digits. The "imagenet" dataset contains more than 1,000,000 training and 100,000 test images of 1,000 different classes. </li>
<li><code>--help</code> or <code>-h</code>: If selected, will show the help message and exit.</li>
<li><code>--blind-inv</code> or <code>-i</code>: Number of blind adversaries inverting their gradients signs. Default: 0.</li>
<li><code>--byzantine</code> or <code>-b</code>: Number of Byzantine adversaries. This number must not be greater than the number of processes minus the number of blind adversaries. Default: 0.</li>
<li><code>--seed</code> or <code>-s</code>: The seed to use everywhere for reproducibility. Default: 42.</li>
<li><code>-net</code> or <code>-n</code>: Name of the neural network from "linregnet", "logregnet", "torchnet, "mnistnet", "resnet18" and "resnet50". "linregnet" is only compatible with linreg dataset, as well as "logregnet" with logreg. "torchnet" and "mnistnet" are compatible with mnist dataset, while "resnet18" and "resnet50" are compatible with imagenet. Default: "mnistnet".</li>
<li><code>--optimizer</code> or <code>-o</code>: Name of the optimizer from "distsgd", "signsgd" and "signum". "distsgd" is the default stochastic gradient descent with a distributed support, "signsgd" is the distributed optimizer detailed in the paper and "signum" is equivalent to "signsgd" with a momentum parameter. Default: "signum".</li>
<li><code>--epochs</code> or <code>-e</code>: Number of training epochs. Default: 10.</li>
<li><code>--lr</code>: Learning rate. Default: 0.001.</li>
<li><code>--lr-decay-step</code>: Number of steps between each modification of the learning rate. Default: 30.</li>
<li><code>--lr-decay_rate</code>: Value by which the learning rate is multiplied every lr_decay_step. Default: 0.1.</li>
<li><code>--momentum</code>: Momentum parameter. Only available for "distsgd" and "signum" optimizers. Default: 0.0.</li>
<li><code>--weight-decay</code>: Weight decay. Only available for "signsgd" and "signum" optimizers. Default: 0.0.</li>
<li><code>--loss</code>: If True, training and test loss for each epoch will be saved in csv files. Verbose argument allows to select if files have to be written only for the mean scores or for each process. Default: True.</li>
<li><code>--acc</code>: If True, training and test accuracy for each epoch will be saved in csv files. Verbose argument allows to select if files have to be written only for the mean scores or for each process. Default: True.</li>
<li><code>--verbose</code> or <code>-v</code>: If 2, will print all metrics of all processes along epochs. If 1, will show a progress bar with the mean scores. If 0, will show a raw progress bar. If loss or acc saving options are True, a verbose of 1 will allow writing files only for the mean scores while a verbose of 2 will allow writing files for each process. Default: 1.</li>
</ul>
<h3 id="plotting-your-results">Plotting your results</h3>
<p>A second file allows to plot comparative graphs of your trained models. The command is as follows:</p>
<pre><code>python3 src/plot_results.py &lt;nprocs&gt; &lt;dataset&gt; &lt;optimizers&gt; &lt;metrics&gt; [options] &lt;subcommands&gt; [suboptions]
</code></pre>
<ul>
<li><code>&lt;nprocs&gt;</code>: Number of processes. This number contains healthy workers as well as eventual adversaries to be set up with optional arguments.</li>
<li><code>&lt;dataset&gt;</code>: Name of the dataset from "linreg", "logreg", "mnist" and "imagenet". The "linreg" and "logreg" datasets are generated internally during the runs and can be used to demonstrate the algorithm. The "mnist" dataset contains 50,000 training and 10,000 test images of size 28x28x1 representing handwritten digits. The "imagenet" dataset contains more than 1,000,000 training and 100,000 test images of 1,000 different classes. </li>
<li><code>&lt;optimizers&gt;</code>: Names of optimizers from "distsgd", "signsgd" and "signum" and separated with commas. "distsgd" is the default stochastic gradient descent with a distributed support, "signsgd" is the distributed optimizer detailed in the paper and "signum" is equivalent to "signsgd" with a momentum parameter. Example: "distsgd,signsgd". Default: "signum".</li>
<li><code>&lt;metrics&gt;</code>: Names of metrics to plot, from "acc" and "loss" and separated with commas. Example: "acc,loss".</li>
<li><code>-net</code> or <code>-n</code>: Name of the neural network from "linregnet", "logregnet", "torchnet, "mnistnet", "resnet18" and "resnet50". "linregnet" is only compatible with linreg dataset, as well as "logregnet" with logreg. "torchnet" and "mnistnet" are compatible with mnist dataset, while "resnet18" and "resnet50" are compatible with imagenet. Default: "mnistnet".</li>
<li><code>--title</code>: If True, will add a title to the graph with the numbers of adversaries in the different runs. Default: False.</li>
<li><code>&lt;subcommands&gt;</code>: Mode of evaluation from "plot" and "comparison". "plot" will create a graph of one distributed setting, if it exists. "comparison" will take several numbers of blind adversaries or several numbers of Byzantine adversaries and plot a comparison of chosen metrics.</li>
<li>plot + <code>--blind-inv</code> or <code>-i</code>: Number of blind adversaries inverting their gradients signs. Default: 0.</li>
<li>plot + <code>--byzantine</code> or <code>-b</code>: Number of Byzantine adversaries. This number must not be greater than the number of processes minus the number of blindadversaries. Default: 0.</li>
<li>comparison + <code>--blind-inv-list</code>: Numbers of blind adversaries separated with commas. Example: 0,1,2,3,4. Default: 0.</li>
<li>comparison + <code>--byzantine-list</code>: Numbers of Byzantine adversaries separated with commas. Example: 0,1,2,3,4. Default: 0.</li>
</ul>
<h2 id="documentation">Documentation</h2>
<p>A complete documentation is available in the <em>doc/src/</em> folder. If it is not
generated, you can run from the root folder:</p>
<pre><code>python3 -m pdoc -o doc/ --html --config latex_math=True --force src/
</code></pre>
<p>Then, open <em>doc/src/index.html</em> in your browser and follow the guide!</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Source code for our evaluation of SignSGD against blind and Byzantine adversaries.

..include:: ../README.md
&#34;&#34;&#34;


import os
import sys


SRC_PATH = os.path.dirname(os.path.abspath(__file__))
sys.path.append(SRC_PATH)  # trick to make pdoc3 understand that this is the package src folder</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="src.datasets" href="datasets/index.html">src.datasets</a></code></dt>
<dd>
<div class="desc"><p>Contain datasets and partitions classes.</p></div>
</dd>
<dt><code class="name"><a title="src.dist_training" href="dist_training.html">src.dist_training</a></code></dt>
<dd>
<div class="desc"><p>Training and evaluation functions are gathered in this file.</p></div>
</dd>
<dt><code class="name"><a title="src.main" href="main.html">src.main</a></code></dt>
<dd>
<div class="desc"><p>Main file to train and evaluate models with distributed optimizers.</p></div>
</dd>
<dt><code class="name"><a title="src.nn" href="nn/index.html">src.nn</a></code></dt>
<dd>
<div class="desc"><p>Contains various neural networks adapted to specific datasets.</p></div>
</dd>
<dt><code class="name"><a title="src.optim" href="optim/index.html">src.optim</a></code></dt>
<dd>
<div class="desc"><p>Contains custom distributed optimizers.</p></div>
</dd>
<dt><code class="name"><a title="src.plot_results" href="plot_results.html">src.plot_results</a></code></dt>
<dd>
<div class="desc"><p>Utilitary functions that allow to plot results.</p></div>
</dd>
<dt><code class="name"><a title="src.utils" href="utils.html">src.utils</a></code></dt>
<dd>
<div class="desc"><p>Gather utilitary functions for randomness control and parameters checking.</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="Directory index" href="index.html">
<img src="logo.png" alt="">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="src.datasets" href="datasets/index.html">src.datasets</a></code></li>
<li><code><a title="src.dist_training" href="dist_training.html">src.dist_training</a></code></li>
<li><code><a title="src.main" href="main.html">src.main</a></code></li>
<li><code><a title="src.nn" href="nn/index.html">src.nn</a></code></li>
<li><code><a title="src.optim" href="optim/index.html">src.optim</a></code></li>
<li><code><a title="src.plot_results" href="plot_results.html">src.plot_results</a></code></li>
<li><code><a title="src.utils" href="utils.html">src.utils</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>